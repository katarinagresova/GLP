{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKOD9lvq5kdM"
      },
      "source": [
        "# PYTORCH CNN Classifier\n",
        "\n",
        "To run this notebook on an another benchmark, use\n",
        "\n",
        "```\n",
        "papermill utils/torch_cnn_character.ipynb torch_cnn_character_experiments/[DATASET NAME].ipynb -p DATASET [DATASET NAME]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E8prt3AL5kdO",
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "DATASET = 'no_dataset'\n",
        "VERSION = 0\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rohBItfR5kdP",
        "outputId": "7da7aafe-0858-48be-bf7d-f698784d88df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "demo_human_or_worm 0 32 1\n"
          ]
        }
      ],
      "source": [
        "print(DATASET, VERSION, BATCH_SIZE, EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-YQrVyb5kdQ"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FIunuyGk5kdR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "from genomic_benchmarks.dataset_getters.pytorch_datasets import get_dataset\n",
        "from genomic_benchmarks.models.torch import CNN\n",
        "from genomic_benchmarks.dataset_getters.utils import coll_factory, LetterTokenizer, build_vocab, check_seq_lengths, check_config, VARIABLE_LENGTH_DATASETS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UgXiF6Zz5kdR"
      },
      "outputs": [],
      "source": [
        "USE_PADDING = DATASET in VARIABLE_LENGTH_DATASETS\n",
        "    \n",
        "config = {\n",
        "    \"dataset\": DATASET,\n",
        "    \"dataset_version\": VERSION,\n",
        "    \"epochs\": EPOCHS,\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"use_padding\": USE_PADDING,\n",
        "    \"force_download\": False,\n",
        "    \"run_on_gpu\": True,\n",
        "    \"number_of_classes\": 2,\n",
        "    \"embedding_dim\": 100,\n",
        "}\n",
        "check_config(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUWF-avz5kdS"
      },
      "source": [
        "## Choose the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oaryDJr5kdS",
        "outputId": "6a425df9-4092-4601-9cd9-f61d524b6278"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading 1Vuc44bXRISqRDXNrxt5lGYLpLsJbrSg8 into /root/.genomic_benchmarks/demo_human_or_worm.zip... "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/genomic_benchmarks/utils/datasets.py:50: UserWarning: No version specified. Using version 0.\n",
            "  warnings.warn(f\"No version specified. Using version {metadata['version']}.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done.\n",
            "Unzipping...Done.\n"
          ]
        }
      ],
      "source": [
        "train_dset = get_dataset(config[\"dataset\"], 'train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0lqmy935kdS"
      },
      "source": [
        "## Tokenizer and vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY_zualp5kdT",
        "outputId": "9034d65f-2f9a-4c83-a314-13d3b808fc65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocab len: 9\n",
            "{'<pad>': 8, '<eos>': 6, 'N': 7, '<bos>': 1, '<unk>': 0, 'C': 2, 'A': 3, 'T': 4, 'G': 5}\n"
          ]
        }
      ],
      "source": [
        "tokenizer = get_tokenizer(LetterTokenizer())\n",
        "vocabulary = build_vocab(train_dset, tokenizer, use_padding=config[\"use_padding\"])\n",
        "\n",
        "print(\"vocab len:\" ,vocabulary.__len__())\n",
        "print(vocabulary.get_stoi())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hGQpSJA5kdT"
      },
      "source": [
        "## Dataloader and batch preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXUgPH6q5kdT",
        "outputId": "a1eb6ba2-9bcd-416d-8662-e3516121da96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "max_seq_len  200\n",
            "not all sequences are of the same length\n"
          ]
        }
      ],
      "source": [
        "# Run on GPU or CPU\n",
        "device = 'cuda' if config[\"run_on_gpu\"] and torch.cuda.is_available() else 'cpu'\n",
        "print('Using {} device'.format(device))\n",
        "\n",
        "max_seq_len, nn_input_len = check_seq_lengths(dataset=train_dset, config=config)\n",
        "\n",
        "# Data Loader\n",
        "if(config[\"use_padding\"]):\n",
        "    collate = coll_factory(vocabulary, tokenizer, device, pad_to_length = nn_input_len)\n",
        "else:\n",
        "    collate = coll_factory(vocabulary, tokenizer, device, pad_to_length = None)\n",
        "\n",
        "train_loader = DataLoader(train_dset, batch_size=config[\"batch_size\"], shuffle=True, collate_fn=collate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTTomnnP5kdU"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZNuXGIdD5kdU"
      },
      "outputs": [],
      "source": [
        "model = CNN(\n",
        "    number_of_classes=config[\"number_of_classes\"],\n",
        "    vocab_size=vocabulary.__len__(),\n",
        "    embedding_dim=config[\"embedding_dim\"],\n",
        "    input_len=nn_input_len\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pqIm92h5kdV"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvO_-RFm5kdV",
        "outputId": "7799e5f9-78a7-4ef2-95e8-f06751912eda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/genomic_benchmarks/dataset_getters/utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(pad(x), dtype=torch.long)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train metrics: \n",
            " Accuracy: 91.4%, Avg loss: 0.543535 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.train(train_loader, epochs=config[\"epochs\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR2tamrc5kdV"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MtBiFLNe7b5U"
      },
      "outputs": [],
      "source": [
        "def test(self, dataloader, positive_label = 1):\n",
        "    size = dataloader.dataset.__len__()\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "    tp, p, fp = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = self(X)\n",
        "            test_loss += self.loss(pred, y).item()\n",
        "            correct += (torch.round(pred) == y).sum().item()\n",
        "            p += (y == positive_label).sum().item() \n",
        "            if(positive_label == 1):\n",
        "                tp += (y * pred).sum(dim=0).item()\n",
        "                fp += ((1 - y) * pred).sum(dim=0).item()\n",
        "            else:\n",
        "                tp += ((1 - y) * (1 - pred)).sum(dim=0).item()\n",
        "                fp += (y * (1 - pred)).sum(dim=0).item()\n",
        "\n",
        "    print(\"p \", p, \"; tp \", tp, \"; fp \", fp)\n",
        "    recall = tp / p\n",
        "    precision = tp / (tp + fp)\n",
        "    print(\"recall \", recall, \"; precision \", precision)\n",
        "    f1_score = 2 * precision * recall / (precision + recall)\n",
        "    \n",
        "    print(\"num_batches\", num_batches)\n",
        "    print(\"correct\", correct)\n",
        "    print(\"size\", size)\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    accuracy = correct / size\n",
        "    print(f\"Test metrics: \\n Accuracy: {accuracy:>6f}, F1 score: {f1_score:>6f}, Avg loss: {test_loss:>6f} \\n\")\n",
        "    \n",
        "    return accuracy, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbnciyRK5kdW",
        "outputId": "d2592f9d-f074-465f-95f8-df3b759ae068"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/genomic_benchmarks/dataset_getters/utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(pad(x), dtype=torch.long)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "p  12500 ; tp  11173.35557794571 ; fp  813.8180167268797\n",
            "recall  0.8938684462356568 ; precision  0.9321092657664888\n",
            "num_batches 782\n",
            "correct 22881\n",
            "size 25000\n",
            "Test metrics: \n",
            " Accuracy: 0.915240, F1 score: 0.912588, Avg loss: 0.542609 \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.91524, 0.9125884238740052)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dset = get_dataset(config[\"dataset\"], 'test')\n",
        "test_loader = DataLoader(test_dset, batch_size=config[\"batch_size\"], shuffle=True, collate_fn=collate)\n",
        "\n",
        "acc, f1 = test(model, test_loader)\n",
        "acc, f1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "torch_cnn_classifier.ipynb",
      "provenance": []
    },
    "environment": {
      "name": "pytorch-gpu.1-9.m75",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m75"
    },
    "interpreter": {
      "hash": "9828b828580f1cac1b571b33de6cff8bacecc8916095e1bcbc967952ca7105b7"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
