{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Genomic_Language_Model.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP3j9wNo7gqJ4iBtgfE1mH7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katarinagresova/genomic_ML_playground/blob/main/Genomic_Language_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPSBWeP--Tk4"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTtWOpv3-Vk_"
      },
      "source": [
        "!pip install biopython\n",
        "!pip install fastai --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF9MmFmBmTlG"
      },
      "source": [
        "On March 15th I was not able to run SubwordTokenizer without installing this manualy first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euXNVN_kmPFq",
        "outputId": "0eb43bea-df40-470e-cc42-d2b93a0a761c"
      },
      "source": [
        "!pip install sentencepiece!=0.1.90,!=0.1.91"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece!=0.1.90,!=0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 6.1MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWxnWzCzENGp",
        "outputId": "70aa1c44-7440-4582-887f-2cc716ca9896"
      },
      "source": [
        "!pip show fastai"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: fastai\n",
            "Version: 2.2.7\n",
            "Summary: fastai simplifies training fast and accurate neural nets using modern best practices\n",
            "Home-page: https://github.com/fastai/fastai/tree/master/\n",
            "Author: Jeremy Howard, Sylvain Gugger, and contributors\n",
            "Author-email: info@fast.ai\n",
            "License: Apache Software License 2.0\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: pandas, scikit-learn, torchvision, torch, packaging, spacy, pip, fastcore, requests, pyyaml, scipy, fastprogress, matplotlib, pillow\n",
            "Required-by: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-qGQ4knjqMF"
      },
      "source": [
        "from Bio import SeqIO\n",
        "from fastai.text.all import *"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLIdViFu-XMR"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5FxJumA9_WQ"
      },
      "source": [
        "Get data that we will use for our language model. For now, we will use human abinition cDNA, since it is small enough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6uCCPq9BWuk",
        "outputId": "a1780bc4-9bf0-41f5-ed7e-9475754c28e2"
      },
      "source": [
        "!wget http://ftp.ensembl.org/pub/release-103/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.abinitio.fa.gz\n",
        "!gunzip Homo_sapiens.GRCh38.cdna.abinitio.fa.gz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-15 06:23:18--  http://ftp.ensembl.org/pub/release-103/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.abinitio.fa.gz\n",
            "Resolving ftp.ensembl.org (ftp.ensembl.org)... 193.62.193.139\n",
            "Connecting to ftp.ensembl.org (ftp.ensembl.org)|193.62.193.139|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20601482 (20M) [application/octet-stream]\n",
            "Saving to: ‘Homo_sapiens.GRCh38.cdna.abinitio.fa.gz’\n",
            "\n",
            "Homo_sapiens.GRCh38 100%[===================>]  19.65M   654KB/s    in 32s     \n",
            "\n",
            "2021-03-15 06:23:50 (633 KB/s) - ‘Homo_sapiens.GRCh38.cdna.abinitio.fa.gz’ saved [20601482/20601482]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwbm96ecBrma"
      },
      "source": [
        "Parse sequences from fasta file into list of sequences. Also put everything to lowercase in case there are mixed upper and lowercase. We don't want our model do learn that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJChAe1HBDNL"
      },
      "source": [
        "with open(\"Homo_sapiens.GRCh38.cdna.abinitio.fa\", \"rt\") as handle:\n",
        "  txts = L(str(record.seq).lower() for record in SeqIO.parse(handle, \"fasta\"))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-89usobMBxQd"
      },
      "source": [
        "We have 51756 sequences, together 64 739 432 characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEPu1oeaBkP4",
        "outputId": "d91de31e-16e8-4666-8e41-6fd86e2510fc"
      },
      "source": [
        "print(len(txts))\n",
        "print(len(''.join(txts)))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51756\n",
            "64739432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phOo3gRDB3r0"
      },
      "source": [
        "Lets look at first sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "QaFMx0_LB6tA",
        "outputId": "397a74c9-594c-45fe-8fe9-9408981f7b8e"
      },
      "source": [
        "txts[0]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'atggaaagaggaaagaagaaaagaatttccaataagttacaacaaacttttcaccattctaaagaacccactttccttatcaaccaagctgggcttctctctagtgactcctattctagcctttccccagaaacagagagtgttaatcctggtgaaaatataaagacagacactcagaaaaagagacctgggactgtgatactatcaaaactgtcaagtagaagaattatatcggaaagccagcttagcccccctgtgatcccggcccgcaggcctggattccgggtatgctatatctgtggccgagaatttgggtcccagtcaattgccattcatgaaccccagtgcttgcagaagtggcatattgaaaacagcaagttgcccaagcatttgaggaggccagaaccctccaaaccacagtctctcagcagcagtgggtcctacagtcttcaggcaactaacgaggctgcatttcagagtgcccaggctcagctgctgccctgtgaatcctgtggccgcacattcttgccagatcatcttcttgttcatcacagaagctgcaagccaaagggtgagggtcccagagcaccacactcaaacagttctgatcatcttactggcctcaagaaagcttgtagtggaaccccagcccgaccaaggactgttatctgctacatatgtggtaaggaatttggcaccctgtcccttcctattcatgagcccaaatgcctggaaaagtggaaaatggaaaatgaccggctccctgtggagctccaccagccactcccacagaagcctcagccccttccgaatgcacagtccagccaagcgggaccaaatcaagctcagcttgtgttctgcccacattgtagccgaatctttacctcagaccgcctcctggtacaccagagaagttgtaaaactcatccttatgggccaaaatatcagaatttgaatttagggagtaaaggaggcctaaaagagtacactaattccaagcagcaaaggaacagggcagcacccagtgtaactgataaggtaattcatgccacacaagacgcattaggtgaacctggtggtgccctctgcctgtag'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmXgPStbirRt"
      },
      "source": [
        "Take 1001st sequence for later testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oswI1SMrWkE4"
      },
      "source": [
        "txt = txts[1001]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71X6YELqFUwa"
      },
      "source": [
        "For even quicker work, lets use just 1000 sequences for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T25V8LrHFaj0"
      },
      "source": [
        "txts = txts[:1000]"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU8szxwRDIM0"
      },
      "source": [
        "# Language model in fastai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sGin2w2uEIn"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "_gGspC56Rzm8",
        "outputId": "d4142ffc-5176-4790-c281-e9de1e95e89b"
      },
      "source": [
        "VOCAB_SIZE = 1000\n",
        "tokenizer = SubwordTokenizer(vocab_sz=VOCAB_SIZE)\n",
        "tokenizer.setup(txts)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sp_model': Path('tmp/spm.model')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b1Xq6imnrPJw",
        "outputId": "db7d3997-e07f-490f-dc55-a26e8bf86248"
      },
      "source": [
        "txt[:100]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'atgcatcagcagccttcggcaaaggggaaacaccgtgcagcagggctgacttggcaaagaggcacccccagaggaatgcgagggcttagagctgcaggca'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgjsbzvfamci",
        "outputId": "7c00f4df-7351-476b-d9aa-43c454fe3912"
      },
      "source": [
        "toks = first(tokenizer([txt]))\n",
        "print(coll_repr(toks, 30))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(#140) ['▁atg','catca','gcag','ccttc','ggcaaa','gg','ggaaa','cacc','gtgcag','cagg','gctg','act','tggc','aaaga','ggcacc','cccag','aggaa','tgc','gaggg','cttag','agctg','caggca','atgcag','ttgct','acac','ggta','tctcag','tgt','caaga','atca'...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWq48ZmFmt-H"
      },
      "source": [
        "Add Tokenizer on top of SubWordTokenizer. Not sure why this is needed, but I wasn't able to run it without this step.\n",
        "\n",
        "I set `rules=[]` so no default rules will be applied - expecialy no encoding of repeating characters.\n",
        "\n",
        "But maybe in future, some custom tokenizer with just special token for start of sequence would be nice. And for unkonown base - N."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7qAgdXXWZYc",
        "outputId": "394b5e11-e82f-439a-bc6a-118d80216620"
      },
      "source": [
        "tkn = Tokenizer(tokenizer, rules=[], sep='')\n",
        "print(coll_repr(tkn(txt), 31))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(#140) ['▁atg','catca','gcag','ccttc','ggcaaa','gg','ggaaa','cacc','gtgcag','cagg','gctg','act','tggc','aaaga','ggcacc','cccag','aggaa','tgc','gaggg','cttag','agctg','caggca','atgcag','ttgct','acac','ggta','tctcag','tgt','caaga','atca','acag'...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-Is2PZ9n3sW",
        "outputId": "0f2ec4c6-c840-4d15-b871-0f8bcad4b700"
      },
      "source": [
        "toks_all = txts.map(tkn)\n",
        "toks_all[0]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁atgg',\n",
              " 'aaaga',\n",
              " 'ggaa',\n",
              " 'agaaga',\n",
              " 'aaagaa',\n",
              " 'tttcca',\n",
              " 'ataa',\n",
              " 'gttac',\n",
              " 'aaca',\n",
              " 'aacttt',\n",
              " 'tcacca',\n",
              " 'ttct',\n",
              " 'aaagaa',\n",
              " 'ccca',\n",
              " 'ctttcc',\n",
              " 'ttat',\n",
              " 'caa',\n",
              " 'ccaag',\n",
              " 'ctggg',\n",
              " 'cttct',\n",
              " 'ctct',\n",
              " 'agtga',\n",
              " 'ctccta',\n",
              " 'ttcta',\n",
              " 'gcct',\n",
              " 'ttccc',\n",
              " 'cagaaa',\n",
              " 'cagag',\n",
              " 'agtg',\n",
              " 'ttaa',\n",
              " 'tcctgg',\n",
              " 'tgaaa',\n",
              " 'atat',\n",
              " 'aaaga',\n",
              " 'cagaca',\n",
              " 'ctc',\n",
              " 'agaaa',\n",
              " 'aagaga',\n",
              " 'cctggg',\n",
              " 'ac',\n",
              " 'tgtga',\n",
              " 'tactat',\n",
              " 'caaa',\n",
              " 'actg',\n",
              " 'tcaagt',\n",
              " 'agaaga',\n",
              " 'att',\n",
              " 'atat',\n",
              " 'cgg',\n",
              " 'aaagcca',\n",
              " 'gctt',\n",
              " 'agcc',\n",
              " 'cccc',\n",
              " 'tgtga',\n",
              " 'tcccg',\n",
              " 'gccc',\n",
              " 'gcagg',\n",
              " 'cctgg',\n",
              " 'att',\n",
              " 'ccggg',\n",
              " 'tatg',\n",
              " 'ctat',\n",
              " 'atct',\n",
              " 'gtggcc',\n",
              " 'gaga',\n",
              " 'attt',\n",
              " 'gggt',\n",
              " 'cccag',\n",
              " 'tcaa',\n",
              " 'ttgcc',\n",
              " 'att',\n",
              " 'catgaac',\n",
              " 'cccag',\n",
              " 'tgct',\n",
              " 'tg',\n",
              " 'cagaag',\n",
              " 'tggcat',\n",
              " 'attga',\n",
              " 'aaa',\n",
              " 'cagcaa',\n",
              " 'gttg',\n",
              " 'cccaag',\n",
              " 'cattt',\n",
              " 'gaggag',\n",
              " 'gccag',\n",
              " 'aacc',\n",
              " 'ctcc',\n",
              " 'aaac',\n",
              " 'cacag',\n",
              " 'tctct',\n",
              " 'cagcagc',\n",
              " 'agtgg',\n",
              " 'gtcc',\n",
              " 'tacag',\n",
              " 'tctt',\n",
              " 'cagg',\n",
              " 'caac',\n",
              " 'taa',\n",
              " 'cgaggc',\n",
              " 'tgc',\n",
              " 'attt',\n",
              " 'cagag',\n",
              " 'tgccca',\n",
              " 'ggct',\n",
              " 'cagctg',\n",
              " 'ctgccc',\n",
              " 'tgtga',\n",
              " 'atcct',\n",
              " 'gtggcc',\n",
              " 'gca',\n",
              " 'ca',\n",
              " 'ttctt',\n",
              " 'gccag',\n",
              " 'atca',\n",
              " 'tcttc',\n",
              " 'ttgt',\n",
              " 'tcatca',\n",
              " 'cagaag',\n",
              " 'ctgc',\n",
              " 'aagcc',\n",
              " 'aaagg',\n",
              " 'gtga',\n",
              " 'gggt',\n",
              " 'cccagag',\n",
              " 'cacc',\n",
              " 'acac',\n",
              " 'tcaaa',\n",
              " 'cagt',\n",
              " 'tctga',\n",
              " 'tcatc',\n",
              " 'ttact',\n",
              " 'ggcctc',\n",
              " 'aagaa',\n",
              " 'agct',\n",
              " 'tgta',\n",
              " 'gtgga',\n",
              " 'accc',\n",
              " 'cagccc',\n",
              " 'gac',\n",
              " 'caaggac',\n",
              " 'tgtt',\n",
              " 'atct',\n",
              " 'gctac',\n",
              " 'atat',\n",
              " 'gtggt',\n",
              " 'aagga',\n",
              " 'attt',\n",
              " 'ggcacc',\n",
              " 'ctgtcc',\n",
              " 'cttcc',\n",
              " 'tattc',\n",
              " 'atga',\n",
              " 'gccc',\n",
              " 'aaatg',\n",
              " 'cctgg',\n",
              " 'aaaagt',\n",
              " 'ggaa',\n",
              " 'aatggaa',\n",
              " 'aatga',\n",
              " 'ccgg',\n",
              " 'ctccc',\n",
              " 'tgtgga',\n",
              " 'gctcca',\n",
              " 'ccagcc',\n",
              " 'actc',\n",
              " 'ccaca',\n",
              " 'gaagc',\n",
              " 'ctcagcc',\n",
              " 'ccttc',\n",
              " 'cg',\n",
              " 'aat',\n",
              " 'gcacag',\n",
              " 'tccag',\n",
              " 'ccaag',\n",
              " 'cggg',\n",
              " 'accaa',\n",
              " 'atca',\n",
              " 'agct',\n",
              " 'cagctt',\n",
              " 'gtgt',\n",
              " 'tctgc',\n",
              " 'ccaca',\n",
              " 'ttgt',\n",
              " 'agcc',\n",
              " 'ga',\n",
              " 'atctt',\n",
              " 'tacct',\n",
              " 'caga',\n",
              " 'ccgcc',\n",
              " 'tcctgg',\n",
              " 'tac',\n",
              " 'acca',\n",
              " 'gagaag',\n",
              " 'ttgt',\n",
              " 'aaaac',\n",
              " 'tcatc',\n",
              " 'ctt',\n",
              " 'atgg',\n",
              " 'gc',\n",
              " 'caaa',\n",
              " 'atat',\n",
              " 'cagaa',\n",
              " 'tttga',\n",
              " 'attt',\n",
              " 'aggg',\n",
              " 'agtaa',\n",
              " 'aggagg',\n",
              " 'cct',\n",
              " 'aaaa',\n",
              " 'gagt',\n",
              " 'acact',\n",
              " 'aatt',\n",
              " 'ccaag',\n",
              " 'cagcaa',\n",
              " 'aggaa',\n",
              " 'caggg',\n",
              " 'cagca',\n",
              " 'cccag',\n",
              " 'tgtaa',\n",
              " 'ctga',\n",
              " 'taa',\n",
              " 'gg',\n",
              " 'taa',\n",
              " 'ttcat',\n",
              " 'gccac',\n",
              " 'acaa',\n",
              " 'gacg',\n",
              " 'catt',\n",
              " 'aggtga',\n",
              " 'acctg',\n",
              " 'gtggt',\n",
              " 'gccc',\n",
              " 'tctgc',\n",
              " 'ctg',\n",
              " 'tag']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FHmEQEtuIB9"
      },
      "source": [
        "## Numericalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYcGQdbMtcH1"
      },
      "source": [
        "Let's translate tokens into numbers.\n",
        "\n",
        "I have here representation of special 'xx' tokens. It is ok for now, but it would be nice to get rid of them in the future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "swmZENhkS2Ka",
        "outputId": "e33c3b17-d695-4a90-84a3-0c5cd9f17b92"
      },
      "source": [
        "num = Numericalize()\n",
        "num.setup(toks_all)\n",
        "coll_repr(num.vocab,20)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"(#1000) ['xxunk','xxpad','xxbos','xxeos','xxfld','xxrep','xxwrep','xxup','xxmaj','tga','taa','tag','gca','cacc','ga','tcctca','ctga','tcag','atga','gtcc'...]\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHVLSCaOtxLb"
      },
      "source": [
        "This is numerical representation of our testing sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu5hMzzLWKyE",
        "outputId": "0e265bae-e6e8-4896-b079-b89d5eec82d5"
      },
      "source": [
        "nums = num(toks)[:20]; nums"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorText([162, 181, 170,  38, 689, 243,  53,  13, 878,  27, 208, 160, 149,  73,\n",
              "        373,  21, 677, 147, 226, 843])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DRCY3WRt29b"
      },
      "source": [
        "Let's put it back to letters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Bm7T5FH3WQ_N",
        "outputId": "d0d003e7-e86d-4dda-bbd1-ba9a7f75c4aa"
      },
      "source": [
        "''.join(num.vocab[o] for o in nums)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'▁atgcatcagcagccttcggcaaaggggaaacaccgtgcagcagggctgacttggcaaagaggcacccccagaggaatgcgagggcttag'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRQgzvQZt8Hs"
      },
      "source": [
        "And compare with original sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "E5K62GXaqcjD",
        "outputId": "1d6f2572-9211-400c-f7a7-799bf773108b"
      },
      "source": [
        "txt[:100]"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'atgcatcagcagccttcggcaaaggggaaacaccgtgcagcagggctgacttggcaaagaggcacccccagaggaatgcgagggcttagagctgcaggca'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    }
  ]
}